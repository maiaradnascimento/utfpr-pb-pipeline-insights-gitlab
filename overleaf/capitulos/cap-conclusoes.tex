% CAPÍTULO 6 - CONCLUSÕES E PERSPECTIVAS
\chapter{Conclusão}\label{cap:conclusoes}

Este trabalho apresentou o desenvolvimento e validação de um sistema para análise inteligente de \textit{pipelines} \gls{cicd} do \gls{gitlab}, com detecção de anomalias e geração de recomendações automáticas, operando exclusivamente com dados de execução coletados via \gls{api}, sem necessidade de acesso ao código-fonte ou arquivos de configuração.

O sistema demonstra que é viável detectar anomalias e gerar recomendações úteis a partir apenas de dados de execução do \gls{gitlab}. A combinação de estatística descritiva (percentis robustos e z-score para normalização) com \gls{ml} não supervisionado (\gls{if}, \gls{kmeans}) fornece sinal explicável e operacionalizável, enquanto o \textit{dashboard} auto-contido acelera a revisão humana.

A arquitetura incremental e \textit{idempotente} garante processamento eficiente, processando apenas novos dados e evitando reprocessamento desnecessário. O \textit{Model Registry} permite versionamento e reprodutibilidade, facilitando evolução e manutenção do sistema.

Do ponto de vista técnico, a escolha de \gls{python}, \gls{postgresql}, \gls{fastapi} e \gls{streamlit} mostrou-se eficiente, conferindo agilidade ao desenvolvimento e facilidade de manutenção. Academicamente e profissionalmente, o sistema comprova sua viabilidade; socialmente, fornece uma ferramenta acessível (\textit{open source}) para apoiar times \gls{devops} na otimização de \textit{pipelines}.

\section{Dificuldades encontradas}\label{sec:dificuldades}

Dentre os principais desafios encontrados:

\begin{itemize}
    \item \textbf{Processamento incremental:} implementação do padrão \textit{Watermark} e \textit{UPSERT} \textit{idempotente} exigiu cuidado para garantir consistência
    \item \textbf{\textit{Feature engineering}:} agregação por \texttt{entity\_key} (\textit{job\_name}) requer atenção para não perder granularidade importante
    \item \textbf{Explicabilidade:} combinar percentis, z-score e evidências numéricas de forma clara e acionável
    \item \textbf{Versionamento de modelos:} garantir reprodutibilidade e compatibilidade entre versões de modelos e \textit{features}
\end{itemize}

\section{Objetivos alcançados}\label{sec:objetivosAlcancados}

Os objetivos específicos foram atingidos:

\begin{enumerate}
    \item \textbf{Coleta e normalização:} sistema coleta dados via \gls{api} do \gls{gitlab} e normaliza em formato estruturado
    \item \textbf{Modelos de detecção:} \gls{if} e \gls{kmeans} implementados e integrados com análise estatística descritiva (percentis robustos e z-score)
    \item \textbf{Recomendações automáticas:} estratégia inteligente gera recomendações com justificativas quantitativas e \textit{links} para evidências
    \item \textbf{\textit{Dashboard}:} \gls{html} auto-contido com visualizações e explicações acessíveis, adequado para revisão rápida
\end{enumerate}

\section{Trabalhos futuros}\label{sec:trabalhosFuturos}

Como sugestão de implementações futuras, recomenda-se:

\begin{itemize}
    \item \textbf{Novos detectores:} LOF (\textit{Local Outlier Factor}), One-Class SVM para diversificar técnicas de detecção de anomalias
    \item \textbf{Otimização de hiperparâmetros:} \textit{Bayesian Optimization} para ajuste automático de hiperparâmetros do \gls{if}
    \item \textbf{Métricas avançadas:} \textit{Cache hit rate} e granularidade de testes (\textit{sharding} por tempo) para recomendações mais precisas
    \item \textbf{Explicabilidade aprimorada:} \gls{xai} local utilizando LIME/SHAP para explicações mais detalhadas das predições
    \item \textbf{Coleta de \textit{logs}:} Coleta sob demanda de \textit{logs} completos (com \textit{quotas} e \textit{rate limiting}) para análise mais profunda
    \item \textbf{Integrações:} \textit{Webhook} do \gls{gitlab}; comentário automático no MR com sumário do \textit{dashboard}
    \item \textbf{Multi-plataforma:} Suporte a outros sistemas \gls{cicd} (GitHub Actions, Jenkins, etc)
    \item \textbf{\textit{Dashboard} interativo:} \textit{Drill-down} e filtros avançados para análise exploratória
    \item \textbf{Recomendações corporativas com LLM:} Desenvolvimento de módulo baseado em \textit{Large Language Models} (LLMs) para geração de recomendações personalizadas baseadas em regras corporativas específicas. Este módulo utilizaria \textit{Retrieval-Augmented Generation} (RAG) para consultar uma base de conhecimento corporativa estruturada, incluindo FAQ interno, base de dados histórica de incidentes e soluções, documentação técnica da organização, e regras de negócio específicas. Esta abordagem permitiria que empresas adaptem o sistema às suas políticas e práticas internas, mantendo os princípios de privacidade e segurança do sistema atual, sem necessidade de expor código-fonte ou configurações sensíveis.
\end{itemize}

\section{Considerações finais}\label{sec:consideracoesFinais}

O sistema desenvolvido oferece uma prova de conceito \textit{open source} com foco em privacidade, explicabilidade e ação. A arquitetura é extensível para novas \textit{features} e modelos, e o código está disponível para contribuições da comunidade.

Como contribuição, o trabalho demonstra a aplicabilidade de IA/\gls{ml} a um problema prático de \gls{devops} com restrição de dados, fomentando pesquisa em observabilidade de \textit{pipelines} e oferecendo uma ferramenta útil para times \gls{devops} que buscam otimizar seus \textit{pipelines} \gls{cicd} sem comprometer segurança ou \textit{compliance}.
