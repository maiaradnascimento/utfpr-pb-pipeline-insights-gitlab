%%%% CAPÍTULO 2 - REVISÃO DA LITERATURA (OU REVISÃO BIBLIOGRÁFICA, ESTADO DA ARTE, ESTADO DO CONHECIMENTO)
%%
%% O autor deve registrar seu conhecimento sobre a literatura básica do assunto, discutindo e comentando a informação já publicada.
%% A revisão deve ser apresentada, preferencialmente, em ordem cronológica e por blocos de assunto, procurando mostrar a evolução do tema.
%% Título e rótulo de capítulo (rótulos não devem conter caracteres especiais, acentuados ou cedilha)
\chapter{Referencial Te\'orico}\label{cap:referencialTeorico}

Este capítulo apresenta conceitos e fundamentos teóricos essenciais para compreensão do trabalho, incluindo \gls{devops} e \gls{cicd}, detecção de anomalias, \gls{xai} e trabalhos relacionados.

\section{DevOps e CI/CD}\label{sec:devopsCICD}

\gls{devops} é uma cultura e conjunto de práticas que combina desenvolvimento de software (Dev) e operações de TI (Ops), visando encurtar o ciclo de vida do desenvolvimento de sistemas e fornecer entrega contínua com alta qualidade \cite{kim2016devops}. A Integração Contínua/Entrega Contínua (\gls{cicd}) é uma prática fundamental do \gls{devops} que automatiza a integração, teste e entrega de código \cite{humble2010continuous,shahin2017continuous,zhang2019continuous}.

Estudos empíricos demonstram que organizações que adotam práticas de \gls{cicd} apresentam melhorias significativas em qualidade de software, tempo de entrega e frequência de \textit{deploy} \cite{kim2018accelerate,wang2019empirical}. A implementação de \textit{pipelines} automatizados reduz erros humanos e acelera o \textit{feedback loop} entre desenvolvimento e operações \cite{chen2015continuous,leite2019survey}.

\textit{Pipelines} \gls{cicd} são sequências automatizadas de etapas (\textit{stages}) e \textit{jobs} que executam tarefas como compilação, testes, análise de código e \textit{deploy}. No \gls{gitlab}, \textit{pipelines} são definidos através de arquivos \texttt{.gitlab-ci.\gls{yaml}} e executados em \textit{runners} (máquinas virtuais ou \textit{containers}).

Apesar dos benefícios da automação, \textit{pipelines} podem apresentar problemas como:
\begin{itemize}
    \item Gargalos de execução (\textit{jobs} lentos que bloqueiam o \textit{pipeline})
    \item Instabilidades (falhas intermitentes, \textit{timeouts})
    \item Retrabalho (re-execuções desnecessárias)
    \item Uso ineficiente de recursos (\textit{cache} não utilizado, paralelização ausente)
\end{itemize}

A observabilidade de \textit{pipelines} é essencial para identificar e corrigir esses problemas, mas muitas vezes requer acesso ao código-fonte ou configurações \gls{yaml}, o que pode ser restritivo em ambientes com políticas de \textit{compliance} rigorosas.

\section{Detecção de anomalias}\label{sec:detecaoAnomalias}

Detecção de anomalias é o processo de identificar padrões em dados que não se conformam ao comportamento esperado \cite{chandola2009anomaly}. Em \textit{pipelines} \gls{cicd}, anomalias podem representar execuções anormalmente lentas, falhas frequentes, ou padrões de uso de recursos incomuns.

\subsection{Isolation Forest}\label{subsec:isolationForest}

\gls{if} é um algoritmo de detecção de anomalias baseado em árvores de decisão que identifica \textit{outliers} através de partições aleatórias do espaço de \textit{features} \cite{liu2008isolation,liu2012isolation}. O algoritmo é eficiente para alta dimensionalidade moderada e não requer dados rotulados, sendo adequado para problemas não supervisionados \cite{chandola2009anomaly,aggarwal2017outlier}.

O \gls{if} funciona isolando observações através de seleção aleatória de \textit{features} e valores de \textit{split}. Anomalias são mais fáceis de isolar (requerem menos partições) do que observações normais, resultando em \textit{scores} de anomalia menores. O algoritmo apresenta complexidade computacional linear O(n), sendo escalável para grandes volumes de dados \cite{liu2012isolation}.

\subsection{Métricas estatísticas}\label{subsec:metricasRobustas}

O sistema utiliza métricas estatísticas para complementar algoritmos de \gls{ml} na priorização e explicabilidade. Percentis (p50, p95, p99) são métricas robustas que fornecem \textit{thresholds} adaptativos baseados na distribuição real dos dados, sendo resistentes a \textit{outliers}. Z-score quantifica o desvio de uma observação em relação à média em termos de desvios-padrão, sendo útil para normalização e análise contextual, embora seja sensível a \textit{outliers} por depender da média e desvio-padrão.

\subsection{\textit{Clustering} (\gls{kmeans})}\label{subsec:clustering}

\gls{kmeans} é um algoritmo de agrupamento não supervisionado que particiona dados em k \textit{clusters} baseado em similaridade \cite{macqueen1967some,han2011data}. No contexto de \textit{pipelines}, \gls{kmeans} pode contextualizar achados por perfis de \textit{pipelines} (curtas, médias, longas), permitindo \textit{thresholds} adaptativos por \textit{cluster} e reduzindo falsos positivos. A validação de \textit{clusters} pode ser realizada através de métricas como \textit{silhouette coefficient} \cite{rousseeuw1987silhouettes}.

\section{XAI aplicada}\label{sec:xaiAplicada}

Inteligência Artificial Explicável (\gls{xai}) refere-se a técnicas que tornam modelos de \gls{ml} interpretáveis e explicáveis para humanos \cite{guidotti2018survey,adadi2018explaining}. No contexto deste trabalho, explicações concisas são geradas combinando percentis, z-score e evidências numéricas, seguindo abordagens de explicabilidade local e global \cite{ribeiro2016should,lundberg2017unified}.

Por exemplo: ``seu \textit{stage test} está 2,7$\sigma$ acima do p50 do \textit{cluster} — sugere paralelização/\texttt{parallel: 4}''. Essas explicações tornam as recomendações acionáveis e justificadas quantitativamente, aumentando a confiança dos engenheiros nas recomendações geradas pelo sistema.

\section{Trabalhos relacionados}\label{sec:trabalhosRelacionados}

A \autoref{tab:trabalhosRelacionados} apresenta uma síntese comparativa entre abordagens existentes e a proposta deste trabalho.

\begin{tabframed}[htb]
\centering
\caption{Comparação entre abordagens existentes e proposta}
\label{tab:trabalhosRelacionados}
\small
\begin{tabular}{|>{\raggedright\arraybackslash}p{2.5cm}|>{\raggedright\arraybackslash}p{4cm}|>{\raggedright\arraybackslash}p{2.5cm}|>{\raggedright\arraybackslash}p{2.5cm}|>{\raggedright\arraybackslash}p{2.5cm}|}
\hline
\textbf{Abordagem} & \textbf{Acesso a código/YAML} & \textbf{Foco} & \textbf{Custo/licença} & \textbf{Explicabilidade} \\ \hline
MCP/MLOps clássicos & Exige acesso & Treino/retreino de modelos & Variável & Média/Alta \\ \hline
Ferramentas APM (Datadog, Dynatrace) & Frequentemente exige & Observabilidade ampla & Pago & Baixa/Média \\ \hline
\textbf{Proposta (este trabalho)} & \textbf{Não exige} & \textbf{\textit{Pipelines} \gls{gitlab}} & \textbf{\textit{Open source}} & \textbf{Alta (percentis + z-score)} \\ \hline
\end{tabular}
\fonte{}
\end{tabframed}

A principal diferença da proposta é operar exclusivamente com dados de execução (\textit{metadados} de \textit{pipelines}/\textit{jobs} e \textit{logs}), sem necessidade de acesso ao código-fonte ou arquivos de configuração, mantendo alta explicabilidade através de métodos estatísticos robustos (percentis) e evidências quantitativas.
